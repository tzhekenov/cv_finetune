{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.cache/pypoetry/virtualenvs/finetune-f9B3-yHi-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import json\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.cache/pypoetry/virtualenvs/finetune-f9B3-yHi-py3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/codespace/.cache/pypoetry/virtualenvs/finetune-f9B3-yHi-py3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Define the dataset class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, json_file, transform=None):\n",
    "        with open(json_file, 'r') as f:\n",
    "            self.data = json.load(f)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        img_path = item['image_path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, idx\n",
    "\n",
    "# Load the pre-trained ResNet50 model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = torch.nn.Identity()  # Modify the model to return embeddings from the penultimate layer\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def compute_embeddings_and_update_json(json_file):\n",
    "    dataset = ImageDataset(json_file, transform=transform)\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for images, idxs in loader:\n",
    "            images = images.to(device)\n",
    "            output = model(images).cpu().numpy().flatten()\n",
    "            embeddings.append((idxs.item(), output))\n",
    "\n",
    "    with open(json_file, 'r+') as f:\n",
    "        data = json.load(f)\n",
    "        for idx, emb in embeddings:\n",
    "            data[idx]['embedding'] = emb.tolist()\n",
    "        f.seek(0)\n",
    "        json.dump(data, f, indent=4)\n",
    "        f.truncate()\n",
    "\n",
    "# Paths to the JSON files\n",
    "json_files = [\n",
    "    '/workspaces/finetune/AFINAL/resnet/image_paths.json',\n",
    "]\n",
    "\n",
    "# Compute embeddings and update JSON files\n",
    "for json_file in json_files:\n",
    "    compute_embeddings_and_update_json(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, json_file, transform=None):\n",
    "        with open(json_file, 'r') as f:\n",
    "            self.data = json.load(f)\n",
    "        self.transform = transform\n",
    "        self.classes = list(set(item['class'] for item in self.data))\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
    "        self.idx_to_class = {idx: cls_name for cls_name, idx in self.class_to_idx.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data[idx]['image_path']\n",
    "        label = self.class_to_idx[self.data[idx]['class']]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ResNet.forward() got an unexpected keyword argument 'return_embedding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 48\u001b[0m\n\u001b[1;32m     43\u001b[0m original_dataset \u001b[38;5;241m=\u001b[39m CustomDataset(json_file\u001b[38;5;241m=\u001b[39moriginal, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#embed_images_and_update_json(model, train_dataset, device, train_json)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m#embed_images_and_update_json(model, val_dataset, device, val_json)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m#embed_images_and_update_json(model, test_dataset, device, test_json)\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m \u001b[43membed_images_and_update_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m, in \u001b[0;36membed_images_and_update_json\u001b[0;34m(model, dataset, device, json_file)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, idxs \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m      8\u001b[0m         images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 9\u001b[0m         embeddings_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_embedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     10\u001b[0m         embeddings\u001b[38;5;241m.\u001b[39mappend((idxs\u001b[38;5;241m.\u001b[39mitem(), embeddings_output))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Update JSON file with embeddings\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/finetune-f9B3-yHi-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/finetune-f9B3-yHi-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: ResNet.forward() got an unexpected keyword argument 'return_embedding'"
     ]
    }
   ],
   "source": [
    "def embed_images_and_update_json(model, dataset, device, json_file):\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, idxs in loader:\n",
    "            images = images.to(device)\n",
    "            embeddings_output = model(images, return_embedding=True).cpu().numpy().flatten()\n",
    "            embeddings.append((idxs.item(), embeddings_output))\n",
    "\n",
    "    # Update JSON file with embeddings\n",
    "    with open(json_file, 'r+') as f:\n",
    "        data = json.load(f)\n",
    "        for idx, emb in embeddings:\n",
    "            data[idx]['embedding'] = emb.tolist()\n",
    "        f.seek(0)\n",
    "        json.dump(data, f, indent=4)\n",
    "        f.truncate()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = torch.nn.Identity()  # Modify the model to return embeddings from the penultimate layer\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Process training and validation data\n",
    "#train_json = '/workspaces/finetune/AFINAL/resnet/output/train_data.json'\n",
    "#val_json = '/workspaces/finetune/AFINAL/resnet/output/val_data.json'\n",
    "#test_json = '/workspaces/finetune/AFINAL/resnet/output/test_data.json'\n",
    "original = '/workspaces/finetune/AFINAL/resnet/image_paths_base.json'\n",
    "\n",
    "#train_dataset = CustomDataset(json_file=train_json, transform=transform)\n",
    "#val_dataset = CustomDataset(json_file=val_json, transform=transform)\n",
    "#test_dataset = CustomDataset(json_file=test_json, transform=transform)\n",
    "original_dataset = CustomDataset(json_file=original, transform=transform)\n",
    "\n",
    "#embed_images_and_update_json(model, train_dataset, device, train_json)\n",
    "#embed_images_and_update_json(model, val_dataset, device, val_json)\n",
    "#embed_images_and_update_json(model, test_dataset, device, test_json)\n",
    "embed_images_and_update_json(model, original_dataset, device, original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top-0 Accuracy: 1.00\n",
      "Average Top-1 Accuracy: 0.96\n",
      "Average Top-2 Accuracy: 0.97\n",
      "Average Top-3 Accuracy: 0.97\n",
      "Average Top-4 Accuracy: 0.97\n",
      "Average Top-5 Accuracy: 0.98\n",
      "Average Top-6 Accuracy: 0.98\n",
      "Average Top-7 Accuracy: 0.98\n",
      "Average Top-8 Accuracy: 0.98\n",
      "Average Top-9 Accuracy: 0.98\n",
      "Average Top-10 Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to load data from JSON file\n",
    "def load_data(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Function to compute Top-K accuracy\n",
    "def compute_top_k_accuracy(query_data, gallery_data, k):\n",
    "    total_queries = len(query_data)\n",
    "    top_k_hits = 0\n",
    "\n",
    "    # Preparing the gallery embeddings and classes\n",
    "    gallery_embeddings = np.array([item['embedding'] for item in gallery_data])\n",
    "    gallery_classes = np.array([item['class'] for item in gallery_data])\n",
    "\n",
    "    # Loop through each query image\n",
    "    for query in query_data:\n",
    "        query_embedding = np.array([query['embedding']])\n",
    "        query_class = query['class']\n",
    "\n",
    "        # Compute cosine similarities between this query and all gallery images\n",
    "        similarities = cosine_similarity(query_embedding, gallery_embeddings)[0]\n",
    "\n",
    "        # Get indices of the top K most similar images\n",
    "        top_k_indices = np.argsort(similarities)[-k:]\n",
    "\n",
    "        # Check if the correct class is within the top K similar images\n",
    "        if query_class in gallery_classes[top_k_indices]:\n",
    "            top_k_hits += 1\n",
    "\n",
    "    # Calculate average Top-K accuracy\n",
    "    top_k_accuracy = top_k_hits / total_queries\n",
    "    return top_k_accuracy\n",
    "\n",
    "# Load datasets\n",
    "test_data = load_data('/workspaces/finetune/AFINAL/resnet/output_base/test_data.json')\n",
    "val_data = load_data('/workspaces/finetune/AFINAL/resnet/output_base/val_data.json')\n",
    "train_data = load_data('/workspaces/finetune/AFINAL/resnet/output_base/train_data.json')\n",
    "\n",
    "# Combine validation and training data into one gallery set\n",
    "gallery_data = val_data + train_data\n",
    "\n",
    "# Set the value of K  # Adjust based on your specific requirements\n",
    "\n",
    "# Compute the Top-K accuracy\n",
    "for k in range(11):\n",
    "    average_top_k_accuracy = compute_top_k_accuracy(test_data, gallery_data, k)\n",
    "    print(f\"Average Top-{k} Accuracy: {average_top_k_accuracy:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top-1 Accuracy: 0.3200\n",
      "Average Top-2 Accuracy: 0.3600\n",
      "Average Top-3 Accuracy: 0.3600\n",
      "Average Top-4 Accuracy: 0.3600\n",
      "Average Top-5 Accuracy: 0.3600\n",
      "Average Top-6 Accuracy: 0.3800\n",
      "Average Top-7 Accuracy: 0.4000\n",
      "Average Top-8 Accuracy: 0.4000\n",
      "Average Top-9 Accuracy: 0.4000\n",
      "Average Top-10 Accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "\n",
    "# Function to load data from JSON file\n",
    "def load_data(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# Function to randomly select query images\n",
    "def select_query_images(data, num_queries=50):\n",
    "    # Filter records with \"image_paths\" length over 2\n",
    "    eligible_data = [record for record in data if len(record['image_paths']) > 2]\n",
    "    # Ensure each class is represented only once\n",
    "    class_seen = set()\n",
    "    filtered_data = []\n",
    "    for record in eligible_data:\n",
    "        if record['class'] not in class_seen:\n",
    "            filtered_data.append(record)\n",
    "            class_seen.add(record['class'])\n",
    "    # Randomly select 50 records from the filtered data\n",
    "    query_images = random.sample(filtered_data, min(num_queries, len(filtered_data)))\n",
    "    return query_images\n",
    "\n",
    "# Function to compute top K accuracy\n",
    "def compute_top_k_accuracy(query_images, all_data, k):\n",
    "    gallery_images = [item for item in all_data if item not in query_images]\n",
    "    gallery_embeddings = np.array([item['embedding'] for item in gallery_images])\n",
    "    gallery_classes = [item['class'] for item in gallery_images]\n",
    "\n",
    "    total_queries = len(query_images)\n",
    "    top_k_hits = 0\n",
    "\n",
    "    for query in query_images:\n",
    "        query_embedding = np.array([query['embedding']])\n",
    "        query_class = query['class']\n",
    "        similarities = cosine_similarity(query_embedding, gallery_embeddings)[0]\n",
    "        top_k_indices = np.argsort(similarities)[-k:]\n",
    "        if query_class in np.array(gallery_classes)[top_k_indices]:\n",
    "            top_k_hits += 1\n",
    "\n",
    "    return top_k_hits / total_queries\n",
    "\n",
    "# Load the data\n",
    "data = load_data('/workspaces/finetune/AFINAL/resnet/image_paths_with_base_embedding.json')\n",
    "\n",
    "# Select query images\n",
    "query_images = select_query_images(data)\n",
    "\n",
    "# Compute the Top-K accuracy\n",
    "for k in range(1,11):\n",
    "    top_k_accuracy = compute_top_k_accuracy(query_images, data, k)  # Adjust K value as needed\n",
    "    print(f\"Average Top-{k} Accuracy: {top_k_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top-1 Accuracy: 0.4168\n",
      "Average Top-5 Accuracy: 0.5043\n",
      "Average Top-10 Accuracy: 0.5409\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to load data from JSON file\n",
    "def load_data(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# Load the datasets\n",
    "query_data = load_data('/workspaces/finetune/AFINAL/resnet/output_base/test_data.json')\n",
    "train_data = load_data('/workspaces/finetune/AFINAL/resnet/output_base/train_data.json')\n",
    "val_data = load_data('/workspaces/finetune/AFINAL/resnet/output_base/val_data.json')\n",
    "image_paths_data = load_data('/workspaces/finetune/AFINAL/resnet/image_paths_base.json')\n",
    "\n",
    "# Combine train and val data for the gallery\n",
    "gallery_data = train_data + val_data\n",
    "\n",
    "# Function to find image paths for exclusion\n",
    "def find_exclusion_paths(image_path):\n",
    "    for record in image_paths_data:\n",
    "        if image_path in record['image_paths']:\n",
    "            return set(record['image_paths'])\n",
    "    return set()\n",
    "\n",
    "# Function to compute top K accuracy\n",
    "def compute_top_k_accuracy(query_data, gallery_data, k):\n",
    "    top_k_hits = 0\n",
    "    total_queries = len(query_data)\n",
    "\n",
    "    for query in query_data:\n",
    "        exclusion_paths = find_exclusion_paths(query['image_path'])\n",
    "        # Filter gallery images: exclude the current query and its transformations\n",
    "        filtered_gallery = [item for item in gallery_data if item['image_path'] not in exclusion_paths]\n",
    "\n",
    "        # Prepare data for similarity computation\n",
    "        query_embedding = np.array([query['embedding']])\n",
    "        gallery_embeddings = np.array([item['embedding'] for item in filtered_gallery])\n",
    "        gallery_classes = [item['class'] for item in filtered_gallery]\n",
    "\n",
    "        # Compute cosine similarities\n",
    "        similarities = cosine_similarity(query_embedding, gallery_embeddings)[0]\n",
    "        top_k_indices = np.argsort(similarities)[-k:]\n",
    "        top_k_classes = np.array(gallery_classes)[top_k_indices]\n",
    "\n",
    "        # Check if the correct class is within the top K similar images\n",
    "        if query['class'] in top_k_classes:\n",
    "            top_k_hits += 1\n",
    "\n",
    "    return top_k_hits / total_queries\n",
    "\n",
    "# Calculate average Top-K accuracy\n",
    "k_values = [1, 5, 10]  # Example K values\n",
    "for k in k_values:\n",
    "    average_top_k_accuracy = compute_top_k_accuracy(query_data, gallery_data, k)\n",
    "    print(f\"Average Top-{k} Accuracy: {average_top_k_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune-f9B3-yHi-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
